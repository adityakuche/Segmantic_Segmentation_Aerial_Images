{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aim-1.using the saved model and predicting the output (i.e. segmented image)\n",
    "    2.saving the segmented out to the local_path\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a8ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#from patchify import patchify, unpatchify\n",
    "#from PIL import Image\n",
    "import segmentation_models as sm\n",
    "\n",
    "from keras.models import load_model #loading the model \n",
    "from smooth_tiled_predictions import predict_img_with_smooth_windowing #this is use to smothing and blending of segmented images\n",
    "from sklearn.preprocessing import MinMaxScaler #scaliing and preprocessing of input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #declaring the object for scaling purpose\n",
    "\n",
    "BACKBONE = 'resnet34' #declaration of base network of resnet34\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121105b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the image\n",
    "img = cv2.imread(r\"C:\\Python310\\tf\\Scripts\\Project_main\\landcover.ai.v1\\Result\\image_s1.tif\")  \n",
    "#scaling the input image and reshapeing it(resizing it)\n",
    "input_img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n",
    "input_img = preprocess_input(input_img)\n",
    "\n",
    "original_mask = cv2.imread(r\"C:\\Python310\\tf\\Scripts\\Project_main\\landcover.ai.v1\\masks\\M-34-6-A-d-2-2.tif\")\n",
    "original_mask = original_mask[:,:,0]  #Use only single channel...\n",
    "#original_mask = to_categorical(original_mask, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aec8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"landcover_2_epochs_RESNET_backbone_batch16.hdf5\", compile=False) #loading the model\n",
    "                  \n",
    "patch_size =256 # size of patches\n",
    "n_classes = 5 # Number of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58cd814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 57s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▌                                                                         | 1/8 [01:02<07:19, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 61s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████                                                               | 2/8 [02:10<06:35, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 61s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▌                                                    | 3/8 [03:18<05:32, 66.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 61s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 4/8 [04:25<04:27, 66.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 58s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████████████████████████▌                               | 5/8 [05:28<03:16, 65.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 59s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 6/8 [06:34<02:11, 65.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 58s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████████████████████████████████████▌          | 7/8 [07:38<01:05, 65.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 57s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [08:42<00:00, 65.34s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_smooth = predict_img_with_smooth_windowing( \n",
    "    input_img,\n",
    "    window_size=patch_size,\n",
    "    subdivisions=2,  # Minimal amount of overlap for windowing. Must be an even number.\n",
    "    nb_classes=n_classes,\n",
    "    pred_func=(lambda img_batch_subdiv: model.predict((img_batch_subdiv))\n",
    "    )\n",
    ")\n",
    "\n",
    "final_prediction = np.argmax(predictions_smooth, axis=2)\n",
    "#MemoryError: Unable to allocate 7.48 GiB for an array with shape (74, 69, 256, 256, 3) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a48613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save prediction and original mask for comparison\n",
    "#\"C:\\Python310\\tf\\Scripts\\Project_main\\landcover.ai.v1\\Result\"\n",
    "plt.imsave(r\"C:\\Python310\\tf\\Scripts\\Project_main\\landcover.ai.v1\\Result\\R2.tiff\",final_prediction)         \n",
    "#plt.imsave('data/test_images/N-34-66-C-c-4-3.tif_mask.jpg', original_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8953129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code is to represent the originalimages, original mask,and predicted segmented images side by side to compare it\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(221)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(img)\n",
    "plt.subplot(222)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(original_mask)\n",
    "plt.subplot(223)\n",
    "plt.title('Prediction with smooth blending')\n",
    "plt.imshow(final_prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117490d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
